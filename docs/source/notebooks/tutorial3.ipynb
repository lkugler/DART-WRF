{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5c3005-f237-4495-9185-2d4d474cafd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial 3: Cycle forecast and assimilation\n",
    "\n",
    "\n",
    "**Goal**: To run a cycled data assimilation experiment.\n",
    "\n",
    "\n",
    "The script [cycled_exp.py](https://github.com/lkugler/DART-WRF/blob/master/cycled_exp.py) contains an example which will be explained here.\n",
    "\n",
    "\n",
    "In this example, we assume that our computing jobs run on a cluster with a \"job scheduler\", so that the jobs don't run immediately, but when there are free resources. This means that we tell each job to wait on another job's completion by using the keyword `depends_on=id`.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "w = WorkFlows(exp_config='cfg.py', server_config='jet.py')\n",
    "\n",
    "timedelta_integrate = dt.timedelta(minutes=15)\n",
    "timedelta_btw_assim = dt.timedelta(minutes=15)\n",
    "\n",
    "    \n",
    "prior_path_exp = '/jetfs/home/lkugler/data/sim_archive/exp_v1.19_P2_noDA'\n",
    "\n",
    "init_time = dt.datetime(2008, 7, 30, 13)\n",
    "time = dt.datetime(2008, 7, 30, 14)\n",
    "last_assim_time = dt.datetime(2008, 7, 30, 14)\n",
    "forecast_until = dt.datetime(2008, 7, 30, 14, 15)\n",
    "\n",
    "w.prepare_WRFrundir(init_time)\n",
    "id = w.run_ideal()\n",
    "\n",
    "prior_init_time = init_time\n",
    "prior_valid_time = time\n",
    "\n",
    "while time <= last_assim_time:\n",
    "\n",
    "    # usually we take the prior from the current time\n",
    "    # but one could use a prior from a different time from another run\n",
    "    # i.e. 13z as a prior to assimilate 12z observations\n",
    "    prior_valid_time = time\n",
    "\n",
    "    id = w.assimilate(time, prior_init_time, prior_valid_time, prior_path_exp, depends_on=id)\n",
    "\n",
    "    # 1) Set posterior = prior\n",
    "    id = w.prepare_IC_from_prior(prior_path_exp, prior_init_time, prior_valid_time, depends_on=id)\n",
    "\n",
    "    # 2) Update posterior += updates from assimilation\n",
    "    id = w.update_IC_from_DA(time, depends_on=id)\n",
    "\n",
    "    # How long shall we integrate?\n",
    "    timedelta_integrate = timedelta_btw_assim\n",
    "    output_restart_interval = timedelta_btw_assim.total_seconds()/60\n",
    "    if time == last_assim_time: #this_forecast_init.minute in [0,]:  # longer forecast every full hour\n",
    "        timedelta_integrate = forecast_until - last_assim_time  # dt.timedelta(hours=4)\n",
    "        output_restart_interval = 9999  # no restart file after last assim\n",
    "\n",
    "    # 3) Run WRF ensemble\n",
    "    id = w.run_ENS(begin=time,  # start integration from here\n",
    "                    end=time + timedelta_integrate,  # integrate until here\n",
    "                    output_restart_interval=output_restart_interval,\n",
    "                    depends_on=id)\n",
    "\n",
    "    # as we have WRF output, we can use own exp path as prior\n",
    "    prior_path_exp = cluster.archivedir       \n",
    "\n",
    "    id_sat = w.create_satimages(time, depends_on=id)\n",
    "\n",
    "    # increment time\n",
    "    time += timedelta_btw_assim\n",
    "\n",
    "    # update time variables\n",
    "    prior_init_time = time - timedelta_btw_assim\n",
    "        \n",
    "w.verify_sat(id_sat)\n",
    "w.verify_wrf(id)\n",
    "w.verify_fast(id)\n",
    "```\n",
    "\n",
    "#### Job scheduling status\n",
    "If you work on a server with a queueing system, the script submits jobs into the SLURM queue with dependencies so that SLURM starts the jobs itself as soon as resources are available. Most jobs need only a few cores, but model integration is done across many nodes. You can look at the status with\n",
    "```bash\n",
    "$ squeue -u `whoami` --sort=i\n",
    "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
    "           1710274  mem_0384 prepwrfr  lkugler PD       0:00      1 (Priority)\n",
    "           1710275  mem_0384 IC-prior  lkugler PD       0:00      1 (Dependency)\n",
    "           1710276  mem_0384 Assim-42  lkugler PD       0:00      1 (Dependency)\n",
    "           1710277  mem_0384 IC-prior  lkugler PD       0:00      1 (Dependency)\n",
    "           1710278  mem_0384 IC-updat  lkugler PD       0:00      1 (Dependency)\n",
    "           1710279  mem_0384 preWRF2-  lkugler PD       0:00      1 (Dependency)\n",
    "    1710280_[1-10]  mem_0384 runWRF2-  lkugler PD       0:00      1 (Dependency)\n",
    "           1710281  mem_0384 pRTTOV-6  lkugler PD       0:00      1 (Dependency)\n",
    "           1710282  mem_0384 Assim-3a  lkugler PD       0:00      1 (Dependency)\n",
    "           1710283  mem_0384 IC-prior  lkugler PD       0:00      1 (Dependency)\n",
    "           1710284  mem_0384 IC-updat  lkugler PD       0:00      1 (Dependency)\n",
    "           1710285  mem_0384 preWRF2-  lkugler PD       0:00      1 (Dependency)\n",
    "    1710286_[1-10]  mem_0384 runWRF2-  lkugler PD       0:00      1 (Dependency)\n",
    "           1710287  mem_0384 pRTTOV-7  lkugler PD       0:00      1 (Dependency)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400244f1-098b-46ea-b29d-2226c7cbc827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwp 2023.1 - 3.10",
   "language": "python",
   "name": "nwp2023.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
